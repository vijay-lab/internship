{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "latest Smriti_scrapper",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijay-lab/internship/blob/master/latest_Smriti_scrapper%20V%202.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDFMmfC6Si4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjwvWwgbSvDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRNP4pTVAKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading ther chrome driver for colab ## driver = webdriver.Chrome('chromedriver',options=options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voZQ_dK_RQMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jul 18 23:44:43 2019\n",
        "\n",
        "@author: TAPAN\n",
        "\"\"\"\n",
        "\n",
        "import selenium\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "\n",
        "\n",
        "letters_val=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','y','z']\n",
        "# 'a','b','c','d','e',\n",
        "\n",
        "columns=['movie','song','singers','lyricist','year','music_director','lyrics']\n",
        "songs_df_main=pd.DataFrame()\n",
        "\n",
        "# setting to run colab headless. \n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(\"chromedriver\",options=options)\n",
        "\n",
        "from selenium.common.exceptions import NoSuchElementException,ElementClickInterceptedException,ElementNotVisibleException\n",
        "\n",
        "for letter in letters_val:\n",
        "    print('currently scraping singers by letter',letter)\n",
        "    address=\"http://smriti.com/hindi-songs/singers-\"+letter  # selects singer letter \n",
        "    driver.get(address)\n",
        "    #singers=[]\n",
        "    songs_df_main=pd.DataFrame()\n",
        "    for singer in range(2,1000):\n",
        "        print(singer-1,'no singer is being scrapped')\n",
        "        try: #clicks on singer name\n",
        "            driver.find_element_by_xpath(f'//*[@id=\"content\"]/div/div/a[{singer}]').click()\n",
        "            total_songs=[]\n",
        "            \n",
        "            total_songs.append(driver.find_elements_by_class_name('onesong'))\n",
        "            no_of_songs=len(total_songs[0])+1\n",
        "            \n",
        "            for elem in range(1,no_of_songs): # this is data downloading block\n",
        "                com_list=[]\n",
        "                print('currently scraping song no:',elem, 'out of',no_of_songs-1)\n",
        "                try:\n",
        "                    \n",
        "                    driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/div[{}]/a[2]'.format(elem)).click()\n",
        "                    \n",
        "                    movie=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/ul/li[1]/a').text\n",
        "                    if not movie:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(movie)\n",
        "                    \n",
        "                    song=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/h1').text\n",
        "                    if not song:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(song)\n",
        "                    singers=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/ul/li[2]').text\n",
        "                    if not singers:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(singers)\n",
        "                        \n",
        "                    lyricist=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/ul/li[4]').text\n",
        "                    if not lyricist:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(lyricist)\n",
        "                        \n",
        "                    year=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/ul/li[6]/a[1]').text\n",
        "                    if not year:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(year)\n",
        "                    try:    \n",
        "                        com_list.append(driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/ul/li[3]/a').text)\n",
        "                    except NoSuchElementException:\n",
        "                        com_list.append(np.nan)\n",
        "                        \n",
        "                    lyrics=driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/div[1]').text\n",
        "                    if not lyrics:\n",
        "                        com_list.append(np.nan)\n",
        "                    else:\n",
        "                        com_list.append(lyrics)\n",
        "                    \n",
        "                    temp_df = pd.DataFrame(com_list).values.reshape(1,-1) \n",
        "                    xx=pd.DataFrame(temp_df,columns=columns)\n",
        "                    \n",
        "                    songs_df_main=pd.concat([songs_df_main,xx], ignore_index=True)\n",
        "                    #songs_df_main.to_csv(f'songs data_{letter}.csv',encoding='utf-8') # Enable this to save songs in csv as they iterate.\n",
        "                    \n",
        "                    driver.back()\n",
        "                except NoSuchElementException:\n",
        "                    \n",
        "                    print(\"oops song doesn't exist.. moving on to next song \")\n",
        "                    pass\n",
        "              \n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    pass\n",
        "                \n",
        "            driver.back() \n",
        "            \n",
        "        except Exception as e:\n",
        "          songs_df_main.to_csv(f'songs data_{letter}.csv',encoding='utf-8') # dumps data to csv after finishing fetching of each letter \n",
        "          print(\"oops singer doesn't exist.. moving on to next page \") \n",
        "          print(e)\n",
        "          driver.back()\n",
        "          pass\n",
        "        \n",
        "        finally :\n",
        "          songs_df_main.to_csv(f'songs data_{letter}.csv',encoding='utf-8') # dumps data to csv after finishing fetching of each letter\n",
        "\n",
        "\n",
        "print('All done ..phew :)')    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}